# Pythonç½‘ç»œçˆ¬è™«ï¼šç­›é€‰æ‹›è˜å²—ä½

## å‰è¨€

æœ¬æ–‡å°†è®²è§£åˆ©ç”¨Pythonç½‘ç»œçˆ¬è™«æµ·é‡æ‹›è˜ä¿¡æ¯ï¼Œä¸€é”®ç­›é€‰ç§°å¿ƒå²—ä½ã€‚

å¦‚æœéœ€è¦æºç å’Œæ•°æ®é›†çš„è¯·ç§ä¿¡ğŸ“§ã€‚

## çŸ¥è¯†ç‚¹

\- requests

\- Beautiful Soup

\- pyecharts

### requests

Requests æ˜¯ä¸€ä¸ª Python çš„ HTTP å®¢æˆ·ç«¯åº“ã€‚åŸºäºurllibç¼–å†™çš„ï¼ŒRequestså®ƒä¼šæ¯”urllibæ›´åŠ æ–¹ä¾¿ï¼Œå¯ä»¥èŠ‚çº¦æˆ‘ä»¬å¤§é‡çš„å·¥ä½œã€‚

### Beautiful Soup

Beautiful Soup æä¾›ä¸€äº›ç®€å•çš„ã€python å¼çš„å‡½æ•°ç”¨æ¥å¤„ç†å¯¼èˆªã€æœç´¢ã€ä¿®æ”¹åˆ†ææ ‘ç­‰åŠŸèƒ½ã€‚å®ƒæ˜¯ä¸€ä¸ªå·¥å…·ç®±ï¼Œé€šè¿‡è§£ææ–‡æ¡£ä¸ºç”¨æˆ·æä¾›éœ€è¦æŠ“å–çš„æ•°æ®ï¼Œå› ä¸ºç®€å•ï¼Œæ‰€ä»¥ä¸éœ€è¦å¤šå°‘ä»£ç å°±å¯ä»¥å†™å‡ºä¸€ä¸ªå®Œæ•´çš„åº”ç”¨ç¨‹åºã€‚Beautiful Soup è‡ªåŠ¨å°†è¾“å…¥æ–‡æ¡£è½¬æ¢ä¸º Unicode ç¼–ç ï¼Œè¾“å‡ºæ–‡æ¡£è½¬æ¢ä¸º utf-8 ç¼–ç ã€‚ä½ ä¸éœ€è¦è€ƒè™‘ç¼–ç æ–¹å¼ï¼Œé™¤éæ–‡æ¡£æ²¡æœ‰æŒ‡å®šä¸€ä¸ªç¼–ç æ–¹å¼ï¼Œè¿™æ—¶ï¼ŒBeautiful Soup å°±ä¸èƒ½è‡ªåŠ¨è¯†åˆ«ç¼–ç æ–¹å¼äº†ã€‚ç„¶åï¼Œä½ ä»…ä»…éœ€è¦è¯´æ˜ä¸€ä¸‹åŸå§‹ç¼–ç æ–¹å¼å°±å¯ä»¥äº†ã€‚Beautiful Soup å·²æˆä¸ºå’Œ lxmlã€html6lib ä¸€æ ·å‡ºè‰²çš„ python è§£é‡Šå™¨ï¼Œä¸ºç”¨æˆ·çµæ´»åœ°æä¾›ä¸åŒçš„è§£æç­–ç•¥æˆ–å¼ºåŠ²çš„é€Ÿåº¦ã€‚

### pyecharts

Echarts æ˜¯ä¸€ä¸ªç”±ç™¾åº¦å¼€æºçš„æ•°æ®å¯è§†åŒ–ï¼Œå‡­å€Ÿç€è‰¯å¥½çš„äº¤äº’æ€§ï¼Œç²¾å·§çš„å›¾è¡¨è®¾è®¡ï¼Œå¾—åˆ°äº†ä¼—å¤šå¼€å‘è€…çš„è®¤å¯ã€‚è€Œ Python æ˜¯ä¸€é—¨å¯Œæœ‰è¡¨è¾¾åŠ›çš„è¯­è¨€ï¼Œå¾ˆé€‚åˆç”¨äºæ•°æ®å¤„ç†ã€‚å½“æ•°æ®åˆ†æé‡ä¸Šæ•°æ®å¯è§†åŒ–æ—¶ï¼Œpyecharts è¯ç”Ÿäº†ã€‚

## çˆ¬è™«æ­¥éª¤

é€šè¿‡å¯¹æ€è·¯çš„åˆ†æï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†å¸®åŠ©è§£å†³é—®é¢˜çš„æ­¥éª¤ï¼š

1. åˆ†æç½‘é¡µï¼Œæ‰¾åˆ°æ•°æ®æ‰€åœ¨ç½‘é¡µä¸­çš„ç»“æ„ï¼›
2. å‘ç½‘é¡µå‘é€è¯·æ±‚ï¼Œè·å–ç½‘é¡µä»£ç ï¼›
3. è§£æç½‘é¡µï¼Œæå–èŒä½åç§°ã€å…¬å¸åç§°å’Œæ‰€åœ¨åŸå¸‚ï¼›
4. ç ´è§£å­—ä½“åçˆ¬è™«ï¼Œæå–è–ªèµ„ï¼›
5. ç»Ÿè®¡ä¸åŒåŸå¸‚çš„å¹³å‡è–ªèµ„ä¸èŒä½æ•°é‡ï¼›
6. ç»˜åˆ¶æŸ±çŠ¶å›¾ï¼Œå¾—å‡ºç»“è®ºã€‚

### å®šä½æ•°æ®

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¦è·å–çš„æ•°æ®æœ‰ï¼šèŒä½åç§°ã€å…¬å¸åç§°ã€å·¥ä½œåœ°å€å’Œå·¥ä½œè–ªèµ„ã€‚

æƒ³è¦çˆ¬å–æ•°æ®ï¼Œé¦–å…ˆè¦å»ç½‘é¡µçš„ HTML ä»£ç ä¸­æ‰¾åˆ°æ‰€åœ¨çš„ä½ç½®ã€‚

åœ¨ HTML ä»£ç ä¸­æˆ‘ä»¬ä¼šå‘ç°ï¼ŒèŒä½åç§°ã€å…¬å¸åç§°å’Œå·¥ä½œåœ°å€æ‰€åœ¨çš„èŠ‚ç‚¹ä¸­ï¼Œè·å–åˆ°äº†ç½‘é¡µçš„æºä»£ç ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦ä½¿ç”¨ BeautifulSoup æ¨¡å—è§£ææºä»£ç ï¼Œæå–å‡ºèŒä½å¯¹åº”çš„ URL é“¾æ¥æ‰€åœ¨çš„å…¨éƒ¨èŠ‚ç‚¹ã€‚

![img](img/ç­›é€‰æ‹›è˜å²—ä½/1.png)

### å¸¸è§åçˆ¬è™«æœºåˆ¶

åœ¨è¿™é‡Œï¼Œç»™å¤§å®¶ä»‹ç»æœ€å¸¸é‡åˆ°çš„ä¸¤ç§åçˆ¬è™«ï¼š

1. åŸºäº User-Agent å­—æ®µ

User-Agent æ˜¯ HTTP è¯·æ±‚å¤´ä¸­ç”¨æ¥è¯†åˆ«ç”¨æˆ·èº«ä»½çš„ä¸€ä¸ªå­—æ®µã€‚

æ¯ä¸ªæ­£å¸¸ç”¨æˆ·ä½¿ç”¨æµè§ˆå™¨æ­£å¸¸è®¿é—®ç½‘ç«™æ—¶éƒ½ä¼šæœ‰æ ‡è¯†è‡ªèº«å±æ€§çš„ User-Agentã€‚è€ŒæœåŠ¡å™¨å¦‚æœå‘ç° User-Agent ä¸ºç©ºæˆ–ä¸æ­£å¸¸ï¼Œåˆ™ä¸€èˆ¬ä¼šæ‹’ç»è¿”å›æ•°æ®ï¼Œå¹¶è¿”å›é”™è¯¯ç  403 è¡¨ç¤ºç¦æ­¢è®¿é—®ã€‚

1. IPè®¿é—®é¢‘ç‡

å¦‚æœè¾“å…¥æ­£ç¡®çš„éªŒè¯ç ï¼Œåˆ™æ”¾è¡Œï¼Œå¦‚æœæ²¡æœ‰è¾“å…¥ï¼Œåˆ™æ‹‰å…¥ç¦æ­¢ä¸€æ®µæ—¶é—´ï¼Œå¦‚æœè¶…è¿‡ç¦çˆ¬æ—¶é—´ï¼Œå†æ¬¡å‡ºå‘éªŒè¯ç ï¼Œåˆ™æ‹‰å…¥é»‘åå•

è®¾ç½®**IP**è®¿é—®é¢‘ç‡ï¼Œå¦‚æœè¶…è¿‡ä¸€å®šé¢‘ç‡ï¼Œå¼¹å‡ºéªŒè¯ç 

3.é™åˆ¶å•ä¸ª**ip/api token**çš„è®¿é—®é‡

ä¸€å®šæ—¶é—´å†…é™åˆ¶è¯·æ±‚çš„è®¿é—®æ¬¡æ•°

### æå–æ•°æ®

ç”¨é¼ æ ‡å®šä½çš„æ–¹æ³•æ‰¾åˆ°æ¯ä¸ªä¿¡æ¯åœ¨ HTML ä»£ç ä¸­çš„ä½ç½®ï¼Œå¯ä»¥å‘ç°æˆ‘ä»¬æƒ³è¦çš„ä¿¡æ¯å°±ä½äºå›¾ä¸­æ‰€ç¤ºçš„èŠ‚ç‚¹ä¸­ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ find() å‡½æ•°ï¼Œåˆ†åˆ«æå–å‡ºèŒä½åç§°ã€å…¬å¸åç§°å’Œæ‰€åœ¨åŸå¸‚å¯¹åº”çš„èŠ‚ç‚¹ã€‚

![img](img/ç­›é€‰æ‹›è˜å²—ä½/2.png)

```
# å¯¼å…¥requestsæ¨¡å—
import requests
# ä»bs4ä¸­å¯¼å…¥BeautifulSoupæ¨¡å—
from bs4 import BeautifulSoup
# å¯¼å…¥timeæ¨¡å—
import time
# å°†User-Agentä»¥å­—å…¸é”®å¯¹å½¢å¼èµ‹å€¼ç»™headers
headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36"}
# å®šä¹‰ä¸€ä¸ªæ–°å‡½æ•°getPositionInfoï¼ŒåŒ…å«å‚æ•°detail_url
def getPositionInfo(detail_url):   
    # å°†detail_urlå’Œheaderså‚æ•°ï¼Œæ·»åŠ è¿›requests.get()ä¸­ï¼Œç»™èµ‹å€¼ç»™res
    res = requests.get(detail_url,headers=headers)
    # ä½¿ç”¨.textå±æ€§è·å–ç½‘é¡µå†…å®¹ï¼Œèµ‹å€¼ç»™html
    html = res.text
    # ç”¨BeautifulSoup()ä¼ å…¥å˜é‡htmlå’Œè§£æå™¨lxmlï¼Œèµ‹å€¼ç»™soup
    soup = BeautifulSoup(html, "lxml")
    # ä½¿ç”¨find()å‡½æ•°è·å–class="new_job_name"çš„èŠ‚ç‚¹
    # ä½¿ç”¨attrså±æ€§æå–å‡ºtitleçš„å±æ€§å€¼,èµ‹å€¼ç»™å˜é‡job
    job = soup.find(class_="new_job_name").attrs["title"]
    # ä½¿ç”¨find()å‡½æ•°è·å–class="com-name"çš„èŠ‚ç‚¹
    # ä½¿ç”¨.stringå±æ€§æå–å‡ºæ ‡ç­¾å†…å®¹
    # ä½¿ç”¨strip()ç§»é™¤ç©ºæ ¼ï¼Œèµ‹å€¼ç»™companyName
    companyName = soup.find(class_="com-name").string.strip()
    # ä½¿ç”¨find()å‡½æ•°è·å–class="job_position"çš„èŠ‚ç‚¹
    # ä½¿ç”¨.stringå±æ€§æå–å‡ºæ ‡ç­¾å†…å®¹ï¼Œèµ‹å€¼ç»™position
    position = soup.find(class_="job_position").string
    # ä½¿ç”¨find()å‡½æ•°è·å–class="job_money cutom_font"çš„èŠ‚ç‚¹
    # ä½¿ç”¨.stringå±æ€§æå–å‡ºæ ‡ç­¾å†…å®¹ï¼Œèµ‹å€¼ç»™salary
    salary = soup.find(class_="job_money cutom_font").string
    # ä½¿ç”¨printæ ¼å¼åŒ–è¾“å‡ºjob,companyName,position,salary
    print(f"{job},{companyName},{position},{salary}")
# forå¾ªç¯éå†range()å‡½æ•°ç”Ÿæˆçš„1-6çš„æ•°å­—
for i in range(1,6):
    # åˆ©ç”¨æ ¼å¼åŒ–å­—ç¬¦ç”Ÿæˆä¸²ç½‘ç«™é“¾æ¥ èµ‹å€¼ç»™å˜é‡url
    url = f"https://www.shixiseng.com/interns?page={i}&type=intern&keyword=%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86&area=&months=&days=&degree=&official=entry&enterprise=&salary=-0&publishTime=&sortType=&city=%E5%85%A8%E5%9B%BD&internExtend="
    # å°†urlå’Œheaderså‚æ•°ï¼Œæ·»åŠ è¿›requests.get()ä¸­ï¼Œå°†å­—å…¸headersä¼ é€’ç»™headerså‚æ•°ï¼Œç»™èµ‹å€¼ç»™res
    res = requests.get(url, headers=headers)
    # ä½¿ç”¨.textå±æ€§è·å–ç½‘é¡µå†…å®¹ï¼Œèµ‹å€¼ç»™html
    html = res.text
    # ç”¨BeautifulSoup()ä¼ å…¥å˜é‡htmlå’Œè§£æå™¨lxmlï¼Œèµ‹å€¼ç»™soup
    soup = BeautifulSoup(html,"lxml")
    # ä½¿ç”¨find_all()æŸ¥è¯¢soupä¸­class=title ellipsis fontçš„èŠ‚ç‚¹ï¼Œèµ‹å€¼ç»™titles
    titles = soup.find_all(class_ = "title ellipsis font")
    # forå¾ªç¯éå†åˆ—è¡¨titles
    for item in titles:
        # ä½¿ç”¨.attrsè·å–hrefå¯¹åº”çš„å±æ€§å€¼ï¼Œå¹¶èµ‹å€¼ç»™detail_url
        detail_url = item.attrs["href"]
        # è°ƒç”¨getPositionInfo()å‡½æ•°ï¼Œä¼ å…¥å‚æ•°detail_url
        getPositionInfo(detail_url)
    # ä½¿ç”¨time.sleep()åœé¡¿2ç§’
    time.sleep(2)
```

## 

### å­—ç¬¦ç¼–ç è½¬æ¢

ä»ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œæœ‰å¥½å¤šæ•°å­—éƒ½æ˜¯å°æ–¹å—ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆæŠŠå°æ–¹æ ¼ç”¨å…¶ä»–çš„ç¼–ç æ–¹å¼é‡æ–°ç¼–ç ï¼Œæ¯”å¦‚è¯´â€œUTF-8â€ç¼–ç ã€‚

æˆ‘ä»¬æ ¹æ®ç¼–ç åçš„äºŒè¿›åˆ¶æ•°æ®ä¸ç½‘é¡µè–ªèµ„æ•°å­—ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œç„¶åå°†å®ƒä»¬è¿›è¡Œæ›¿æ¢ã€‚

æ¥ç€å°†äºŒè¿›åˆ¶æ•°æ®ï¼Œå†è½¬æ¢æˆå­—ç¬¦ä¸²ï¼Œå°±å¯ä»¥ç ´è§£å­—ä½“åçˆ¬è™«æœºåˆ¶ï¼Œè·å–åˆ°è–ªèµ„æ•°æ®å•¦ï½

æƒ³è¦å°†å­—ç¬¦ä¸²è½¬æ¢æˆäºŒè¿›åˆ¶æ•°æ®ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ encode() å‡½æ•°ï¼Œå®ç°â€œç¼–ç â€ã€‚

åœ¨ encode() å‡½æ•°ä¸­é»˜è®¤ UTF-8 ç¼–ç ï¼Œç”±äºå®ƒæ˜¯é’ˆå¯¹è‹±è¯­è®¾è®¡çš„ï¼Œä¸­è‹±æ–‡å­—ç¬¦è½¬ç åä¼šæœ‰å·®å¼‚ã€‚

æ›¿æ¢å®Œæˆåï¼Œæ¥ä¸‹æ¥å°±è¦å°†æ–°çš„äºŒè¿›åˆ¶æ•°æ®è½¬æ¢æˆå­—ç¬¦ä¸²ï¼Œè¿™ä¸ªè¿‡ç¨‹å°±å«åšâ€œè§£ç â€ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ decode() å‡½æ•°ã€‚

ä»£ç å¦‚ä¸‹ï¼š

```
# ä½¿ç”¨find()å‡½æ•°è·å–class="job_money cutom_font"çš„èŠ‚ç‚¹
# ä½¿ç”¨.stringå±æ€§æå–å‡ºæ ‡ç­¾å†…å®¹ï¼Œèµ‹å€¼ç»™salary
salary= soup.find(class_="job_money cutom_font").string

# encode()å‡½æ•°å¯¹å˜é‡salaryç¼–ç ï¼Œèµ‹å€¼ç»™salary
salary = salary.encode()

# ä½¿ç”¨replace()å‡½æ•°å°†äºŒè¿›åˆ¶æ•°æ®æ›¿æ¢æˆUTF-8ç¼–ç æ•°å­—
salary = salary.replace(b"\xee\x8b\xbf", b"0")
salary = salary.replace(b"\xee\xa2\x9c", b"1")
salary = salary.replace(b"\xee\x90\xb7", b"2")

# ä½¿ç”¨printè¾“å‡ºsalary
print(salary)
```

### æ•°æ®ç»Ÿè®¡

æƒ³è¦ç»˜åˆ¶ä¸åŒåŸå¸‚çš„å¹³å‡è–ªèµ„æŸ±çŠ¶å›¾ï¼Œæˆ‘ä»¬å…ˆè¦çŸ¥é“æŸ±çŠ¶å›¾çš„ x è½´å’Œ y è½´çš„æ•°æ®æ˜¯ä»€ä¹ˆã€‚

è¿™é‡ŒæŸ±çŠ¶å›¾çš„ x è½´æ˜¯ä¸åŒçš„åŸå¸‚åï¼Œy è½´æ˜¯å¹³å‡è–ªèµ„ã€‚

æŸ±å°†æ•°æ®è¿›è¡Œå¤„ç†æ”¾åœ¨ä¸¤ä¸ªå­—å…¸ä¸­ï¼Œå­—å…¸cityDictçš„é”®ä¸ºä¸åŒåŸå¸‚ï¼Œå¯¹åº”çš„å€¼ä¸ºå¹³å‡è–ªèµ„ã€‚å­—å…¸ city_num_dict çš„é”®ä¸ºä¸åŒåŸå¸‚ï¼Œå¯¹åº”çš„å€¼ä¸ºèŒä½æ•°é‡ã€‚

ä» pyecharts.charts ä¸­å¯¼å…¥ Bar æ¨¡å—ï¼Œè¿›è¡Œæ•°æ®å¯è§†åŒ–ç»˜åˆ¶å‡ºä¸¤ä¸ªæŸ±çŠ¶å›¾ã€‚

![img](img/ç­›é€‰æ‹›è˜å²—ä½/3.png)ä»£ç å¦‚ä¸‹ï¼š

```
# ä»pyecharts.chartsä¸­å¯¼å…¥Baræ¨¡å—
from pyecharts.charts import Bar
# ä½¿ç”¨with...asè¯­å¥é…åˆopen()å‡½æ•°ä»¥ræ–¹å¼ï¼Œæ‰“å¼€è·¯å¾„ä¸ºâ€œ/Users/èŒä½æ•°æ®.txtâ€çš„æ–‡ä»¶ï¼Œèµ‹å€¼ç»™f
with open("/Users/èŒä½æ•°æ®.txt", "r") as f:
    # ä½¿ç”¨readlines()è¯»å–fä¸­çš„æ‰€æœ‰è¡Œï¼Œèµ‹å€¼ç»™dataList
    dataList = f.readlines()
# æ–°å»ºä¸€ä¸ªå­—å…¸cityDict
cityDict = {}
# forå¾ªç¯éå†åˆ—è¡¨dataListä¸­çš„æ¯ä¸ªå…ƒç´ data
for data in dataList:
    # å¦‚æœ"è–ªèµ„é¢è®®"åœ¨å…ƒç´ ä¸­
    if "è–ªèµ„é¢è®®" in data:
        # å°±è·³è¿‡
        continue
    # ä½¿ç”¨split()ä»¥é€—å·åˆ†éš”dataï¼Œç´¢å¼•ç¬¬3é¡¹å…ƒç´ ï¼Œèµ‹å€¼ç»™city
    city = data.split(",")[2]
    # ä½¿ç”¨split()ä»¥é€—å·åˆ†éš”dataï¼Œç´¢å¼•ç¬¬4é¡¹å…ƒç´ ï¼Œèµ‹å€¼ç»™salary
    salary = data.split(",")[3]
    # ä½¿ç”¨split()ä»¥æ–œæ åˆ†éš”salaryï¼Œç´¢å¼•ç¬¬1é¡¹å…ƒç´ ï¼Œèµ‹å€¼ç»™daily
    daily = salary.split("/")[0]
    # ä½¿ç”¨split()ä»¥çŸ­æ¨ªçº¿åˆ†éš”dailyç´¢å¼•ç¬¬1é¡¹ï¼Œèµ‹å€¼ç»™start
    start = daily.split("-")[0]
    # ä½¿ç”¨split()ä»¥çŸ­æ¨ªçº¿åˆ†éš”dailyç´¢å¼•ç¬¬2é¡¹ï¼Œèµ‹å€¼ç»™end
    end = daily.split("-")[1]
    # å°†startå’Œendè½¬æ¢æˆæ•´å‹ç›¸åŠ åé™¤ä»¥2ï¼Œå¹¶èµ‹å€¼ç»™average
    average = (int(start)+int(end))/2
    # å¦‚æœcityä¸åœ¨å­—å…¸cityDictçš„é”®ä¸­
    if city not in cityDict.keys():
        # å°†å­—å…¸ä¸­é”®æ‰€å¯¹åº”çš„å€¼è®¾ç½®ä¸ºç©ºåˆ—è¡¨
        cityDict[city] = []
    # ä½¿ç”¨append()å‡½æ•°å¾€å­—å…¸é”®æ‰€å¯¹åº”çš„å€¼ä¸­æ·»åŠ average
    cityDict[city].append(average)
# æ–°å»ºä¸€ä¸ªå­—å…¸city_num_dict
city_num_dict = {}
# forå¾ªç¯éå†cityDict.items()ä¸­çš„key,value
for key,value in cityDict.items():
    # ä½¿ç”¨sum()å‡½æ•°å°†åˆ—è¡¨valueæ±‚å’Œ
    # ä½¿ç”¨len()å‡½æ•°è®¡ç®—åˆ—è¡¨valueé•¿åº¦
    # ä½¿ç”¨//è¿ç®—ç¬¦è®¡ç®—åˆ—è¡¨valueçš„å¹³å‡å€¼ï¼Œèµ‹å€¼ç»™average_value
    average_value = sum(value)//len(value)
    # å°†å­—å…¸cityDictçš„é”®å¯¹åº”çš„å€¼è®¾ç½®ä¸ºaverage_value
    cityDict[key] = average_value
    # å°†å­—å…¸city_num_dictçš„é”®è®¾ç½®ä¸ºä¸åŒåŸå¸‚
    # å°†å¯¹åº”çš„å€¼è®¾ç½®ä¸ºlen(value)
    city_num_dict[key] = len(value)
# åˆ›å»ºBarå¯¹è±¡ï¼Œèµ‹å€¼ç»™bar
bar = Bar()
# ä½¿ç”¨list()å°†å­—å…¸cityDictæ‰€æœ‰é”®è½¬æ¢æˆåˆ—è¡¨ï¼Œä¼ å…¥add_xaxis()ä¸­
bar.add_xaxis(list(cityDict.keys()))
# ä½¿ç”¨add_yaxis()å‡½æ•°ï¼Œå°†æ•°æ®ç»Ÿç§°è®¾ç½®ä¸º"åŸå¸‚"
# å°†å­—å…¸cityDictæ‰€æœ‰å€¼è½¬æ¢æˆåˆ—è¡¨ï¼Œä½œä¸ºå‚æ•°æ·»åŠ è¿›å‡½æ•°ä¸­
bar.add_yaxis("åŸå¸‚",list(cityDict.values()))
# ä½¿ç”¨render()å‡½æ•°å­˜å‚¨æ–‡ä»¶ï¼Œè®¾ç½®æ–‡ä»¶åä¸ºsalary.html
bar.render("salary.html")
# åˆ›å»ºBarå¯¹è±¡ï¼Œèµ‹å€¼ç»™bar_city
bar_city = Bar()
# ä½¿ç”¨list()å°†å­—å…¸city_num_dictæ‰€æœ‰é”®è½¬æ¢æˆåˆ—è¡¨ï¼Œä¼ å…¥add_xaxis()ä¸­
bar_city.add_xaxis(list(city_num_dict.keys()))
# ä½¿ç”¨add_yaxis()å‡½æ•°ï¼Œå°†æ•°æ®ç»Ÿç§°è®¾ç½®ä¸º"åŸå¸‚"
# å°†å­—å…¸city_num_dictæ‰€æœ‰å€¼è½¬æ¢æˆåˆ—è¡¨ï¼Œä½œä¸ºå‚æ•°æ·»åŠ è¿›å‡½æ•°ä¸­
bar_city.add_yaxis("åŸå¸‚",list(city_num_dict.values()))
# ä½¿ç”¨render()å‡½æ•°å­˜å‚¨æ–‡ä»¶ï¼Œè®¾ç½®æ–‡ä»¶åä¸ºpositions.html
bar_city.render("positions.html")
```

## æ€»ç»“

æœ¬æ–‡è®²è§£äº†åˆ†æç½‘é¡µï¼Œè§£æç½‘é¡µï¼Œå­—ç¬¦ä¸²ç¼–ç è½¬æ¢ï¼Œè¯»å–æ•°æ®ï¼Œæ•°æ®ç»Ÿè®¡ï¼Œç»˜åˆ¶æŸ±çŠ¶å›¾ã€‚

<img src="img/weixin.png" alt="img" style="zoom:50%;" />